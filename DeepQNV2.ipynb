{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepQNV2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTcquVU567aLr5W6DCO8rr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skeletrox/dl_notebook/blob/master/DeepQNV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHXttOYX_zTa",
        "colab_type": "text"
      },
      "source": [
        "# 3x3 Treasure Hunter\n",
        "\n",
        "Uses DQL to perform a treasure hunt given static treasure and enemy. Ideally the agent should avoid any cells that pertain to the enemy and directly go towards the treasure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSSeGmYPA7E4",
        "colab_type": "text"
      },
      "source": [
        "## Basic Imports\n",
        "\n",
        "Numpy for numerical computation\n",
        "\n",
        "Random for random functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4qKraaxrbjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWOvP5cNBzzp",
        "colab_type": "text"
      },
      "source": [
        "## Pytorch imports\n",
        "\n",
        "Import the neural network module and the Variable class (just for convenience)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0otgQTggrg--",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gPBRnq7LadW",
        "colab_type": "text"
      },
      "source": [
        "This is the decision-making neural network. The number of percepts and the number of actions are parameters to modify the input size and the output size based on the problem.\n",
        "\n",
        "Since this is a neural network that implements Pytorch's Module class, the `forward` method has to be defined, which just describes a single execution of the neural network; a forward propagation step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0A1AitnrmI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(nn.Module):\n",
        "  def __init__(self, perceptSize, actionSize):\n",
        "    super(DQN, self).__init__()\n",
        "    self.perceptSize = perceptSize\n",
        "    self.actionSize = actionSize\n",
        "    self.structure = nn.Sequential(\n",
        "      nn.Linear(self.perceptSize, 128),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(128, 256),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(256, 128),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(128, self.actionSize)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.structure(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT4WOhvvPcCF",
        "colab_type": "text"
      },
      "source": [
        "The `ExpBuffer` is used to store experiences in a deque. As training continues, the deque fills up and slowly replaces old observations with newer ones, improving the model performance.\n",
        "\n",
        "The `push` method adds new samples to the buffer.\n",
        "\n",
        "The `sample` method samples a number of observations randomly from the buffer and returns them to the training algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4UPsizVtbx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import deque\n",
        "\n",
        "class ExpBuffer:\n",
        "\n",
        "  def __init__(self, capacity):\n",
        "    self.capacity = capacity\n",
        "    self.buffer = deque(maxlen=capacity)\n",
        "\n",
        "  def push(self, state, action, reward, nextState, done):\n",
        "    experience = (state, action, np.array([reward]), nextState, done)\n",
        "    self.buffer.append(experience)\n",
        "\n",
        "  def generate(self, batchSize):\n",
        "    # Build batch\n",
        "    for i in range(batchSize):\n",
        "      currState = np.array([np.random.randint(3) for i in range(numInputs)])\n",
        "      currentAction = np.random.randint(numActions)\n",
        "      nextState, reward, done = simulate(currState, currentAction)\n",
        "      self.push(currState, currentAction, reward, nextState, done)\n",
        "\n",
        "  def sample(self, batchSize):\n",
        "    stateBatch = []\n",
        "    actionBatch = []\n",
        "    rewardBatch = []\n",
        "    nextStateBatch = []\n",
        "    doneBatch = []\n",
        "\n",
        "    batch = random.sample(self.buffer, batchSize)\n",
        "\n",
        "    for experience in batch:\n",
        "      state, action, reward, nextState, done = experience\n",
        "      stateBatch.append(state)\n",
        "      actionBatch.append(action)\n",
        "      rewardBatch.append(reward)\n",
        "      nextStateBatch.append(nextState)\n",
        "      doneBatch.append(done)\n",
        "\n",
        "    return (stateBatch, actionBatch, rewardBatch, nextStateBatch, doneBatch)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.buffer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQV-xaYESfVb",
        "colab_type": "text"
      },
      "source": [
        "The agent is the decision maker in the field. it contains a network (something similar to the planning component of your brain) and a buffer (comparable to your memory). The agent generates experiences in the buffer and then samples values in order to improve its prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u27qlRsPBIQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent:\n",
        "\n",
        "\n",
        "  def __init__(self, perceptSize, numActions, alpha, gamma, bufferSize):\n",
        "    self.perceptSize = perceptSize\n",
        "    self.numActions = numActions\n",
        "    self.alpha = alpha\n",
        "    self.gamma = gamma\n",
        "    self.bufferSize = bufferSize\n",
        "    self.buffer = ExpBuffer(self.bufferSize)\n",
        "    self.network = DQN(perceptSize, numActions)\n",
        "    if torch.cuda.is_available():\n",
        "      print(\"Exploiting CUDA availability.\")\n",
        "      self.network.cuda()\n",
        "    self.optimizer = torch.optim.Adam(self.network.parameters(), lr=alpha)\n",
        "    self.MSE_loss = nn.MSELoss()\n",
        "    self.losses = []\n",
        "\n",
        "\n",
        "  def getAction(self, state):\n",
        "    state = Variable(torch.from_numpy(state).float().unsqueeze(0))\n",
        "    qvals = self.network.forward(state)\n",
        "    action = np.argmax(qvals.detach().numpy())\n",
        "    return action\n",
        "\n",
        "\n",
        "  def computeLoss(self, batch):\n",
        "    states, actions, rewards, nextStates, dones = batch\n",
        "    states = torch.FloatTensor(states).cuda()\n",
        "    actions = torch.LongTensor(actions).cuda()\n",
        "    rewards = torch.FloatTensor(rewards).cuda()\n",
        "    nextStates = torch.FloatTensor(nextStates).cuda()\n",
        "    dones = torch.FloatTensor(dones).cuda()\n",
        "    currQ = self.network.forward(states).gather(1, actions.unsqueeze(1))\n",
        "    currQ = currQ.squeeze(1)\n",
        "    nextQ = self.network.forward(nextStates)\n",
        "    maxNextQ = torch.max(nextQ, 1)[0]\n",
        "    expectedQ = rewards.squeeze(1) + (1 - dones) * self.gamma * maxNextQ\n",
        "    loss = self.MSE_loss(currQ, expectedQ.detach())\n",
        "    return loss\n",
        "\n",
        "  \n",
        "  def update(self, batchSize):\n",
        "    self.buffer.generate(batchSize)\n",
        "    batch = self.buffer.sample(batchSize)\n",
        "    loss = self.computeLoss(batch)\n",
        "    self.losses.append(loss.item()) \n",
        "    self.optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    self.optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuAS_sUUJ0at",
        "colab_type": "text"
      },
      "source": [
        "This is the simulation function. Given a state and an action, it returns the next state, the corresponding reward for the action, and whether or not the state is terminal, i.e. there is nothing more left to do."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FugLQHFQSZfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the simulator function.\n",
        "def simulate(state, action):\n",
        "\n",
        "  x = state[0]\n",
        "  y = state[1]\n",
        "\n",
        "  badReward = -1000\n",
        "  goodReward = 1000\n",
        "\n",
        "  # Got gored by a monster\n",
        "  if x == 2 and y == 2:\n",
        "    return state, badReward, True\n",
        "  \n",
        "  # Got the treasure\n",
        "  if x == 2 and y == 0:\n",
        "    return state, goodReward, True\n",
        "\n",
        "  if action == 0: # Going Left\n",
        "    x -= 1\n",
        "  elif action == 1: # Going Right\n",
        "    x += 1\n",
        "  elif action == 2:\n",
        "    y += 1 # Going down\n",
        "  else:\n",
        "    y -= 1 # Going up\n",
        "\n",
        "  # Define boundary crossing penalties\n",
        "  reward = 0\n",
        "  if x < 0:\n",
        "    x = 0\n",
        "    reward = badReward\n",
        "  elif x > 2:\n",
        "    x = 2\n",
        "    reward = badReward\n",
        "  elif y < 0:\n",
        "    y = 0\n",
        "    reward = badReward\n",
        "  elif y > 2:\n",
        "    y = 2\n",
        "    reward = badReward\n",
        "  \n",
        "  return np.array([x, y]), reward, False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwYX64kSaKmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The inputs are x and y\n",
        "numInputs = 2\n",
        "\n",
        "# The Q values are for up, down, left, right\n",
        "numActions = 4\n",
        "\n",
        "# Define a learning rate and gamma as well\n",
        "alpha = 0.005\n",
        "gamma = 0.9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi6YJ6C5TUho",
        "colab_type": "code",
        "outputId": "a08891e9-4cdb-4523-f844-1452a9bd6c61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "agent = Agent(numInputs, numActions, alpha, gamma, 10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exploiting CUDA availability.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auBoaM2BtX1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# how many epochs?\n",
        "epochs = 10000\n",
        "\n",
        "# what is the batch size?\n",
        "batchSize = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfVdTVTk6KmJ",
        "colab_type": "code",
        "outputId": "1edf179d-f8d0-4759-e500-6edd5e6749fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "values = []\n",
        "\n",
        "for i in range(1, epochs+1):\n",
        "  agent.update(batchSize)\n",
        "  z = np.mean(agent.losses[-batchSize:])\n",
        "  values.append(z)\n",
        "  if i % 100 == 0:\n",
        "    print(\"Epoch number: {}, Loss: {}\".format(i, z))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number: 100, Loss: 285534.04875\n",
            "Epoch number: 200, Loss: 148133.94203125\n",
            "Epoch number: 300, Loss: 71446.19115234374\n",
            "Epoch number: 400, Loss: 39468.0181640625\n",
            "Epoch number: 500, Loss: 23265.26771484375\n",
            "Epoch number: 600, Loss: 9292.081821289063\n",
            "Epoch number: 700, Loss: 3031.8421228027346\n",
            "Epoch number: 800, Loss: 2551.1877215576174\n",
            "Epoch number: 900, Loss: 4047.5766284179685\n",
            "Epoch number: 1000, Loss: 6816.394985351562\n",
            "Epoch number: 1100, Loss: 3022.528687133789\n",
            "Epoch number: 1200, Loss: 7792.6376599121095\n",
            "Epoch number: 1300, Loss: 5737.8447265625\n",
            "Epoch number: 1400, Loss: 13024.30166015625\n",
            "Epoch number: 1500, Loss: 14122.533676757812\n",
            "Epoch number: 1600, Loss: 13743.580795898437\n",
            "Epoch number: 1700, Loss: 9176.350712890626\n",
            "Epoch number: 1800, Loss: 1182.1974891662599\n",
            "Epoch number: 1900, Loss: 542.5534422302246\n",
            "Epoch number: 2000, Loss: 198.79090745925905\n",
            "Epoch number: 2100, Loss: 39.292420110702516\n",
            "Epoch number: 2200, Loss: 7.7038589334487915\n",
            "Epoch number: 2300, Loss: 5.062380889654159\n",
            "Epoch number: 2400, Loss: 2.8002522227168085\n",
            "Epoch number: 2500, Loss: 0.4319505517184734\n",
            "Epoch number: 2600, Loss: 0.46423561215400694\n",
            "Epoch number: 2700, Loss: 3.378777083158493\n",
            "Epoch number: 2800, Loss: 7.081721770763397\n",
            "Epoch number: 2900, Loss: 12.181657164096832\n",
            "Epoch number: 3000, Loss: 6.288340406417847\n",
            "Epoch number: 3100, Loss: 41.27412600517273\n",
            "Epoch number: 3200, Loss: 174.54369327545166\n",
            "Epoch number: 3300, Loss: 337.7609370422363\n",
            "Epoch number: 3400, Loss: 5370.854915771484\n",
            "Epoch number: 3500, Loss: 11725.185317382813\n",
            "Epoch number: 3600, Loss: 10371.639875488281\n",
            "Epoch number: 3700, Loss: 7018.276179199219\n",
            "Epoch number: 3800, Loss: 11560.805830078125\n",
            "Epoch number: 3900, Loss: 9788.756767578125\n",
            "Epoch number: 4000, Loss: 8135.6275\n",
            "Epoch number: 4100, Loss: 6818.89890625\n",
            "Epoch number: 4200, Loss: 4714.147586669922\n",
            "Epoch number: 4300, Loss: 6934.488308105469\n",
            "Epoch number: 4400, Loss: 4862.575610351562\n",
            "Epoch number: 4500, Loss: 2961.2661096191405\n",
            "Epoch number: 4600, Loss: 997.5893026733398\n",
            "Epoch number: 4700, Loss: 383.68976753234864\n",
            "Epoch number: 4800, Loss: 82.5729088306427\n",
            "Epoch number: 4900, Loss: 13.727960815429688\n",
            "Epoch number: 5000, Loss: 12.965595126152039\n",
            "Epoch number: 5100, Loss: 3.527412179708481\n",
            "Epoch number: 5200, Loss: 1.3644329607486725\n",
            "Epoch number: 5300, Loss: 0.8371063318848609\n",
            "Epoch number: 5400, Loss: 1.4636514300107957\n",
            "Epoch number: 5500, Loss: 3.1092765700817107\n",
            "Epoch number: 5600, Loss: 14.712064945697785\n",
            "Epoch number: 5700, Loss: 26.76402398109436\n",
            "Epoch number: 5800, Loss: 125.04795492172241\n",
            "Epoch number: 5900, Loss: 561.0135006713867\n",
            "Epoch number: 6000, Loss: 3187.8425579833984\n",
            "Epoch number: 6100, Loss: 12861.87236328125\n",
            "Epoch number: 6200, Loss: 5273.644506835937\n",
            "Epoch number: 6300, Loss: 1401.4671115112305\n",
            "Epoch number: 6400, Loss: 400.1756539916992\n",
            "Epoch number: 6500, Loss: 70.51049072265624\n",
            "Epoch number: 6600, Loss: 9.364696538448333\n",
            "Epoch number: 6700, Loss: 3.9686261916160586\n",
            "Epoch number: 6800, Loss: 1.2167875108122825\n",
            "Epoch number: 6900, Loss: 0.33030073165893553\n",
            "Epoch number: 7000, Loss: 0.10113739129155874\n",
            "Epoch number: 7100, Loss: 0.14062030833214523\n",
            "Epoch number: 7200, Loss: 0.15800189457833766\n",
            "Epoch number: 7300, Loss: 0.13345515299588442\n",
            "Epoch number: 7400, Loss: 0.29587654031813143\n",
            "Epoch number: 7500, Loss: 1.0261646264791489\n",
            "Epoch number: 7600, Loss: 0.6950025555491447\n",
            "Epoch number: 7700, Loss: 0.5440130607783794\n",
            "Epoch number: 7800, Loss: 0.43432467199862\n",
            "Epoch number: 7900, Loss: 1.1840721249580384\n",
            "Epoch number: 8000, Loss: 5.394001731872558\n",
            "Epoch number: 8100, Loss: 8.519383115768433\n",
            "Epoch number: 8200, Loss: 17.94854802131653\n",
            "Epoch number: 8300, Loss: 38.66209289550781\n",
            "Epoch number: 8400, Loss: 1896.6645425415038\n",
            "Epoch number: 8500, Loss: 12034.561801757813\n",
            "Epoch number: 8600, Loss: 1516.4577506256103\n",
            "Epoch number: 8700, Loss: 142.4530031967163\n",
            "Epoch number: 8800, Loss: 77.45972930908204\n",
            "Epoch number: 8900, Loss: 12.941694140434265\n",
            "Epoch number: 9000, Loss: 3.2473955535888672\n",
            "Epoch number: 9100, Loss: 1.1541038233041763\n",
            "Epoch number: 9200, Loss: 0.9324594041705132\n",
            "Epoch number: 9300, Loss: 0.5563290756940842\n",
            "Epoch number: 9400, Loss: 0.4889343513548374\n",
            "Epoch number: 9500, Loss: 0.3954233871400356\n",
            "Epoch number: 9600, Loss: 0.4551828097552061\n",
            "Epoch number: 9700, Loss: 0.1250600217655301\n",
            "Epoch number: 9800, Loss: 0.037766659893095494\n",
            "Epoch number: 9900, Loss: 0.04089716537855566\n",
            "Epoch number: 10000, Loss: 0.10866580305621028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myzNj8bq-Udz",
        "colab_type": "code",
        "outputId": "3fdf25b4-7938-445c-8f30-d7e676cfe6d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f27a491fc50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEclJQSEiIjn9J6eftLl5KHVoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TpGr99RSrhp",
        "colab_type": "code",
        "outputId": "740378fc-e7cb-497f-ee2e-569ad8da81d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "from itertools import product\n",
        "predicted = None\n",
        "with torch.no_grad():\n",
        "  indices = [i for i in range(3)]\n",
        "  for x, y in product(indices, indices):\n",
        "    vals = np.array([x, y])\n",
        "    predicted = agent.network(Variable(torch.from_numpy(vals).float().cuda())).cpu().numpy()\n",
        "    # predicted = agent.network(Variable(torch.from_numpy(vals)))\n",
        "    maxRewardResults = np.argmax(predicted)\n",
        "    print(\"For x = {}; y = {}; Predicted rewards: {}\".format(x, y, predicted))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For x = 0; y = 0; Predicted rewards: [-271.2611   810.7267   656.4166  -270.40433]\n",
            "For x = 0; y = 1; Predicted rewards: [-344.12933  729.875    591.1323   729.81854]\n",
            "For x = 0; y = 2; Predicted rewards: [-409.5605   656.98566 -409.20184  657.09143]\n",
            "For x = 1; y = 0; Predicted rewards: [ 729.1149   900.6348   729.3381  -189.65413]\n",
            "For x = 1; y = 1; Predicted rewards: [656.27167 810.5126  656.6403  810.4524 ]\n",
            "For x = 1; y = 2; Predicted rewards: [ 590.84045 -899.14435 -343.72482  729.66815]\n",
            "For x = 2; y = 0; Predicted rewards: [ 999.8701  1000.41187 1000.135    999.68427]\n",
            "For x = 2; y = 1; Predicted rewards: [ 729.18604 -189.46783 -899.32227  900.831  ]\n",
            "For x = 2; y = 2; Predicted rewards: [ -999.15027  -999.467   -1000.1943   -998.8887 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SYosKSoA9HK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LlVGHtfVdyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}